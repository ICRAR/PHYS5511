{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "keras-cnn_week06.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICRAR/PHYS5511/blob/master/2019/week06/keras_cnn_week06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aise1X95DRzr",
        "colab_type": "text"
      },
      "source": [
        "A baseline solution of the GalaxZoo competition adapted from [this kernel](https://www.kaggle.com/helmehelmuto/keras-cnn/notebook)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaNTulbTDzmt",
        "colab_type": "text"
      },
      "source": [
        "#Machine setup\n",
        "Make sure to change the Runtime --> runtime type to \"GPU\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjXflUP0C32A",
        "colab_type": "text"
      },
      "source": [
        "#Mount G-drive filesystem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94SXB1svvWDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqGTZuQPJDXb",
        "colab_type": "text"
      },
      "source": [
        "#Solution overview\n",
        "Before getting started, please provide an overview of your thinking processes to tackle the problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-j-31ogvIPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WEeFpjAllJC",
        "colab_type": "text"
      },
      "source": [
        "#Basic setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syIHGG48PN7O",
        "colab_type": "text"
      },
      "source": [
        "Check [the winner paper](https://arxiv.org/abs/1503.07077) about cropping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gDaZ0dXlkUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# please modify this root_path\n",
        "root_path = '/content/drive/My Drive/PHYS5512/data/galaxy_zoo'\n",
        "ORIG_SHAPE = (424, 424)\n",
        "CROP_SIZE = (256, 256)\n",
        "IMG_SHAPE = (64, 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq9ZNEIeJjeB",
        "colab_type": "text"
      },
      "source": [
        "#Load catalogues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBGxr8_gCRVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "training_solution_file = osp.join(root_path, 'training_solutions_rev1.csv')\n",
        "df = pd.read_csv(training_solution_file)\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=.2)\n",
        "df_train.shape, df_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbd8DyP8LkdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimated_origin_size = ORIG_SHAPE[0] * ORIG_SHAPE[1] * 3 * df_train.shape[0]\n",
        "estimated_crop_size = CROP_SIZE[0] * CROP_SIZE[1] * 3 * df_train.shape[0]\n",
        "reshaped_size = IMG_SHAPE[0] * IMG_SHAPE[1] * 3 * df_train.shape[0]\n",
        "print('Original training size:\\t %.2f GBytes' \\\n",
        "      % (estimated_origin_size / 1024 ** 3))\n",
        "print('Cropped training size:\\t %.2f GBytes' \\\n",
        "      % (estimated_crop_size / 1024 ** 3))\n",
        "print('Reshaped training size:\\t %.2f GBytes' \\\n",
        "      % (reshaped_size / 1024 ** 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNigGOLhCVn7",
        "colab_type": "text"
      },
      "source": [
        "#Data preprocessing (no unzip required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQVX0yKHIqUe",
        "colab_type": "text"
      },
      "source": [
        "Please make sure you understand what is going on with the cropping and resizing here. To show your understanding, consider making a few plots on the original image, the cropped version and the resized version, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bcdDR1rvIPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_image(path, x1, y1, shape, crop_size):\n",
        "    x = plt.imread(path)\n",
        "    #print(x.shape)\n",
        "    x = x[x1:x1 + crop_size[0], y1:y1 + crop_size[1]]\n",
        "    x = resize(x, shape)\n",
        "    #x = x / 255. # comment this out\n",
        "    return x\n",
        "    \n",
        "def get_all_images(dataframe, shape=IMG_SHAPE, crop_size=CROP_SIZE):\n",
        "    x1 = (ORIG_SHAPE[0] - CROP_SIZE[0]) // 2\n",
        "    y1 = (ORIG_SHAPE[1] - CROP_SIZE[1]) // 2\n",
        "   \n",
        "    sel = dataframe.values\n",
        "    ids = sel[:, 0].astype(int).astype(str)\n",
        "    y_batch = sel[:, 1:]\n",
        "    x_batch = []\n",
        "    filename = osp.join(root_path, 'images_training_rev1.zip')\n",
        "    with ZipFile(filename) as archive:\n",
        "      for i in tqdm(ids):\n",
        "          fn = archive.open('images_training_rev1/{0}.jpg'.format(i))\n",
        "          x = get_image(fn, x1, y1, shape=shape, crop_size=crop_size)\n",
        "          x_batch.append(x)\n",
        "      x_batch = np.array(x_batch)\n",
        "    return x_batch, y_batch\n",
        "        \n",
        "X_train, y_train = get_all_images(df_train)\n",
        "X_test, y_test = get_all_images(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOHJGodmlpPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = (X_train * 255).astype(np.uint8)\n",
        "X_test = (X_test * 255).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWCZfDT5A24A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lb, arr in zip(['X_train', 'y_train', 'X_test', 'y_test'], [X_train, y_train, X_test, y_test]):\n",
        "  npfn = osp.join(root_path, '%s.npy' % lb)\n",
        "  np.save(npfn, arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ylTuK62By6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!du -sh '{root_path}/X_train.npy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrKVQuLr9Zrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.load(osp.join(root_path, 'X_train.npy'))\n",
        "y_train = np.load(osp.join(root_path, 'y_train.npy'))\n",
        "X_test = np.load(osp.join(root_path, 'X_test.npy'))\n",
        "y_test = np.load(osp.join(root_path, 'y_test.npy'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAUKaouHAuRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ar in [X_train, y_train, X_test, y_test]:\n",
        "  print(ar.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc4r_o_pCzZQ",
        "colab_type": "text"
      },
      "source": [
        "##visualise the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P69IBrEboBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind_check = np.random.choice(len(X_train), 3)\n",
        "plt.figure(figsize=(15, 6))\n",
        "for i, idx in enumerate(ind_check):\n",
        "  plt.subplot(1, 3, i + 1)\n",
        "  plt.imshow(X_train[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTbftWq-KaO6",
        "colab_type": "text"
      },
      "source": [
        "##Interprete the label\n",
        "Use the [Galaxy Zoo paper](https://arxiv.org/pdf/1308.3496.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8WwxAITIyC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[ind_check[2]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mEIkAIGCvDV",
        "colab_type": "text"
      },
      "source": [
        "#Build the basic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mZ1vSg9rZqO",
        "colab_type": "text"
      },
      "source": [
        "Please make sure explain your model with some reasonalbly detailed rationales. For example:\n",
        "1. why use \"root mean squre error\" as the metrics?\n",
        "2. what is *binary_crossentropy*, why can't we use *categorical_crossentropy* that we used in [Tutorial 04](https://colab.research.google.com/github/ICRAR/PHYS5511/blob/master/2019/week04/Keras_FC_network_classifier.ipynb)?\n",
        "3. What happens if we use *mean_squared_error* as the loss?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLXEAFv4vIPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalMaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "  return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(512, (3, 3), input_shape=(IMG_SHAPE[0], IMG_SHAPE[1], 3)))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(GlobalMaxPooling2D())\n",
        "\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(37))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# why can't we\n",
        "# model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=[root_mean_squared_error])\n",
        "# why can't we \n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=[root_mean_squared_error])\n",
        "#model.compile(loss='mean_squared_error', optimizer='adamax', metrics=[root_mean_squared_error])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEi0eRbRCykG",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPzgsIK9vIPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "small_train_set = 10000 # please remove this \"small\" setup\n",
        "small_val_set = 1000\n",
        "nb_epochs = 5\n",
        "X_train = X_train.astype(np.float32) / 255 # why?\n",
        "X_test = X_test.astype(np.float32) / 255  # why?\n",
        "history = model.fit(X_train[0:small_train_set, :, :], y_train[0:small_train_set], \n",
        "                    epochs=nb_epochs, batch_size=batch_size, \n",
        "                    validation_data=(X_test[0:small_val_set, :, :], y_test[0:small_val_set]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtda28DAP28K",
        "colab_type": "text"
      },
      "source": [
        "#Plot training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXBLGuybBeiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.ticker import MaxNLocator\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.gca()\n",
        "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "histories = history.history.items()\n",
        "xvals = np.arange(1, nb_epochs + 1)\n",
        "for k, v in histories:\n",
        "    plt.plot(xvals, v, label=k if 'val_' in k else 'train_%s' % k)\n",
        "\n",
        "plt.legend(loc='best', fontsize=14)\n",
        "plt.suptitle('Loss curve', fontsize=16)\n",
        "plt.ylabel('MSE', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPpTttAevIPM",
        "colab_type": "text"
      },
      "source": [
        "# Test Prediction Submission (change me to get it working)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBviHLkBvIPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def test_image_generator(ids, shape=IMG_SHAPE):\n",
        "    x1 = (ORIG_SHAPE[0] - CROP_SIZE[0]) // 2\n",
        "    y1 = (ORIG_SHAPE[1] - CROP_SIZE[1]) // 2\n",
        "    x_batch = []\n",
        "    for i in ids:\n",
        "        x = get_image('../input/44352/images_test_rev1/'+i, x1, y1, shape=IMG_SHAPE, crop_size=CROP_SIZE)\n",
        "        x_batch.append(x)\n",
        "    x_batch = np.array(x_batch)\n",
        "    return x_batch\n",
        "\n",
        "val_files = os.listdir('../input/44352/images_test_rev1/')\n",
        "val_predictions = []\n",
        "N_val = len(val_files)\n",
        "for i in tqdm(np.arange(0, N_val, batch_size)):\n",
        "    if i+batch_size > N_val:\n",
        "        upper = N_val\n",
        "    else:\n",
        "        upper = i+batch_size\n",
        "    X = test_image_generator(val_files[i:upper])\n",
        "    y_pred = model.predict(X)\n",
        "    val_predictions.append(y_pred)\n",
        "val_predictions = np.array(val_predictions)\n",
        "Y_pred = np.vstack(val_predictions)\n",
        "ids = np.array([v.split('.')[0] for v in val_files]).reshape(len(val_files),1)\n",
        "submission_df = pd.DataFrame(np.hstack((ids, Y_pred)), columns=df.columns)\n",
        "submission_df = submission_df.sort_values(by=['GalaxyID'])\n",
        "submission_df.to_csv('sample_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2D2kHAwKecG",
        "colab_type": "text"
      },
      "source": [
        "#Lessons learnt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD1-iwwiKor5",
        "colab_type": "text"
      },
      "source": [
        "1. Summary of the most important know-how you leanred from this assignment?\n",
        "2. Are there any limitations of the current solution?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CGiPuKjKy86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}