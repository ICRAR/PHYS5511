{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "keras-cnn_week06_02.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICRAR/PHYS5511/blob/master/2019/week06/keras_cnn_week06_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aise1X95DRzr",
        "colab_type": "text"
      },
      "source": [
        "A more scalabe solution of the GalaxZoo competition based on [the basic solution](https://github.com/ICRAR/PHYS5511/blob/master/2019/week06/keras_cnn_week06.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaNTulbTDzmt",
        "colab_type": "text"
      },
      "source": [
        "#Machine setup\n",
        "Make sure runtime type is always \"GPU\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjXflUP0C32A",
        "colab_type": "text"
      },
      "source": [
        "#Mount G-drive filesystem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94SXB1svvWDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqGTZuQPJDXb",
        "colab_type": "text"
      },
      "source": [
        "#Solution overview\n",
        "Before getting started, please provide an overview of your thinking processes to tackle the problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-j-31ogvIPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import os.path as osp\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WEeFpjAllJC",
        "colab_type": "text"
      },
      "source": [
        "#Basic setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syIHGG48PN7O",
        "colab_type": "text"
      },
      "source": [
        "Check [the winner paper](https://arxiv.org/abs/1503.07077) about cropping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gDaZ0dXlkUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# please modify this root_path\n",
        "root_path = '/content/drive/My Drive/PHYS5512/data/galaxy_zoo'\n",
        "ORIG_SHAPE = (424, 424)\n",
        "CROP_SIZE = (256, 256)\n",
        "IMG_SHAPE = (64, 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq9ZNEIeJjeB",
        "colab_type": "text"
      },
      "source": [
        "#Load catalogues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBGxr8_gCRVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "training_solution_file = osp.join(root_path, 'training_solutions_rev1.csv')\n",
        "df = pd.read_csv(training_solution_file)\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=.2)\n",
        "df_train.shape, df_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbd8DyP8LkdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimated_origin_size = ORIG_SHAPE[0] * ORIG_SHAPE[1] * 3 * df_train.shape[0]\n",
        "estimated_crop_size = CROP_SIZE[0] * CROP_SIZE[1] * 3 * df_train.shape[0]\n",
        "reshaped_size = IMG_SHAPE[0] * IMG_SHAPE[1] * 3 * df_train.shape[0]\n",
        "print('Original training size:\\t %.2f GBytes' \\\n",
        "      % (estimated_origin_size / 1024 ** 3))\n",
        "print('Cropped training size:\\t %.2f GBytes' \\\n",
        "      % (estimated_crop_size / 1024 ** 3))\n",
        "print('Reshaped training size:\\t %.2f GBytes' \\\n",
        "      % (reshaped_size / 1024 ** 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D5gtkFktm_7",
        "colab_type": "text"
      },
      "source": [
        "#Scalable Image Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcgU74TuEpi",
        "colab_type": "text"
      },
      "source": [
        "First we define a zip image generator (iterator). Every `next()` call will produce a batch of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GqpfPjPtq3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zip_image_generator(dataframe, batch_size, aug=None):\n",
        "  index_counter = 0\n",
        "  filename = osp.join(root_path, 'images_training_rev1.zip')\n",
        "  df = dataframe.values\n",
        "  nb_imgs = df.shape[0]\n",
        "  print(index_counter)\n",
        "  with ZipFile(filename) as archive:\n",
        "    while True:\n",
        "      x_batch = []\n",
        "      y_batch = []\n",
        "      while (len(x_batch) < batch_size):\n",
        "        ind = index_counter % nb_imgs\n",
        "        gid = str(int(df[ind][0]))\n",
        "        #print(gid)\n",
        "        fn = archive.open('images_training_rev1/{0}.jpg'.format(gid))\n",
        "        x = plt.imread(fn) / 255.0\n",
        "        h, w, c = x.shape\n",
        "        x = np.reshape(x, [1, h, w, c])\n",
        "        y = df[ind][1:]\n",
        "        x_batch.append(x)\n",
        "        y_batch.append(y)\n",
        "        index_counter += 1\n",
        "      yield (np.vstack(x_batch), np.vstack(y_batch))\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrONWyRU7xfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_gen = zip_image_generator(df_train, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g52ASd5y2qbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs, labels = next(zip_gen)\n",
        "print(imgs.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mEIkAIGCvDV",
        "colab_type": "text"
      },
      "source": [
        "#Build the basic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mZ1vSg9rZqO",
        "colab_type": "text"
      },
      "source": [
        "Please make sure explain your model with some reasonalbly detailed rationales. For example:\n",
        "1. why use \"root mean squre error\" as the metrics?\n",
        "2. what is *binary_crossentropy*, why can't we use *categorical_crossentropy* that we used in [Tutorial 04](https://colab.research.google.com/github/ICRAR/PHYS5511/blob/master/2019/week04/Keras_FC_network_classifier.ipynb)?\n",
        "3. What happens if we use *mean_squared_error* as the loss?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLXEAFv4vIPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, GlobalMaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "  return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(512, (3, 3), input_shape=(ORIG_SHAPE[0], ORIG_SHAPE[1], 3)))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(GlobalMaxPooling2D())\n",
        "\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(37))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# why can't we\n",
        "# model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=[root_mean_squared_error])\n",
        "# why can't we \n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=[root_mean_squared_error])\n",
        "#model.compile(loss='mean_squared_error', optimizer='adamax', metrics=[root_mean_squared_error])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEi0eRbRCykG",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPzgsIK9vIPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 4\n",
        "small_train_set = 10000 # please remove this \"small\" setup\n",
        "small_val_set = 1000\n",
        "nb_epochs = 5\n",
        "train_gen = zip_image_generator(df_train, batch_size)\n",
        "val_gen = zip_image_generator(df_test, batch_size)\n",
        "history = model.fit_generator(train_gen, steps_per_epoch=small_train_set // batch_size,\n",
        "                             validation_data=val_gen, validation_steps=small_val_set // batch_size,\n",
        "                             epochs=nb_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtda28DAP28K",
        "colab_type": "text"
      },
      "source": [
        "#Plot training curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXBLGuybBeiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.ticker import MaxNLocator\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.gca()\n",
        "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "histories = history.history.items()\n",
        "xvals = np.arange(1, nb_epochs + 1)\n",
        "for k, v in histories:\n",
        "    plt.plot(xvals, v, label=k if 'val_' in k else 'train_%s' % k)\n",
        "\n",
        "plt.legend(loc='best', fontsize=14)\n",
        "plt.suptitle('Loss curve', fontsize=16)\n",
        "plt.ylabel('MSE', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT_VFF4IP9EH",
        "colab_type": "text"
      },
      "source": [
        "#Plot more learning curves?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jqc2AF5QBU6",
        "colab_type": "text"
      },
      "source": [
        "1. Can you try plotting the learning curve and analyise the trade-off between variance and bias as shown on Slide 27 at [Week 03](https://lms.uwa.edu.au/bbcswebdav/pid-133298-dt-announcement-rid-21639517_1/xid-21639517_1)? \n",
        "\n",
        "(Tips - by increasing the variable *small_train_set*)\n",
        "\n",
        "2. If time permitted, you could also try to locate the \"optimal capacity\" as shown on Slide 26 at [Week 03](https://lms.uwa.edu.au/bbcswebdav/pid-133298-dt-announcement-rid-21639517_1/xid-21639517_1)? \n",
        "\n",
        "(Tips - by decreasing / increasing more CNN / FC layers in the model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPpTttAevIPM",
        "colab_type": "text"
      },
      "source": [
        "# Test Prediction Submission (change me to get it working)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBviHLkBvIPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def test_image_generator(ids, shape=IMG_SHAPE):\n",
        "    x1 = (ORIG_SHAPE[0] - CROP_SIZE[0]) // 2\n",
        "    y1 = (ORIG_SHAPE[1] - CROP_SIZE[1]) // 2\n",
        "    x_batch = []\n",
        "    for i in ids:\n",
        "        x = get_image('../input/44352/images_test_rev1/'+i, x1, y1, shape=IMG_SHAPE, crop_size=CROP_SIZE)\n",
        "        x_batch.append(x)\n",
        "    x_batch = np.array(x_batch)\n",
        "    return x_batch\n",
        "\n",
        "val_files = os.listdir('../input/44352/images_test_rev1/')\n",
        "val_predictions = []\n",
        "N_val = len(val_files)\n",
        "for i in tqdm(np.arange(0, N_val, batch_size)):\n",
        "    if i+batch_size > N_val:\n",
        "        upper = N_val\n",
        "    else:\n",
        "        upper = i+batch_size\n",
        "    X = test_image_generator(val_files[i:upper])\n",
        "    y_pred = model.predict(X)\n",
        "    val_predictions.append(y_pred)\n",
        "val_predictions = np.array(val_predictions)\n",
        "Y_pred = np.vstack(val_predictions)\n",
        "ids = np.array([v.split('.')[0] for v in val_files]).reshape(len(val_files),1)\n",
        "submission_df = pd.DataFrame(np.hstack((ids, Y_pred)), columns=df.columns)\n",
        "submission_df = submission_df.sort_values(by=['GalaxyID'])\n",
        "submission_df.to_csv('sample_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2D2kHAwKecG",
        "colab_type": "text"
      },
      "source": [
        "#Lessons learnt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD1-iwwiKor5",
        "colab_type": "text"
      },
      "source": [
        "1. Summary of the most important know-how you leanred from this assignment?\n",
        "2. Are there any limitations of the current solution?"
      ]
    }
  ]
}