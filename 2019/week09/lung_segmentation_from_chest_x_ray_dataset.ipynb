{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "lung-segmentation-from-chest-x-ray-dataset.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICRAR/PHYS5511/blob/master/2019/week09/lung_segmentation_from_chest_x_ray_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3e31b44d0a51ce86eddf4487c2e63a99e9128742",
        "id": "tnDZt8KoASVO",
        "colab_type": "text"
      },
      "source": [
        "#Lung segmentation from Chest X-Ray dataset\n",
        "\n",
        "**About the data**:\n",
        "- The [dataset](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4256233/) is made up of images and segmentated mask from two diffrent sources.\n",
        "- There is a slight abnormality in naming convention of masks.\n",
        "- Some images don't have their corresponding masks.\n",
        "- Images from the Shenzhen dataset has apparently smaller lungs as compared to the Montgomery dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dp19-YuA8cK",
        "colab_type": "text"
      },
      "source": [
        "This Notebook was adapted from this [Kaggle kernel](https://www.kaggle.com/nikhilpandey360/lung-segmentation-from-chest-x-ray-dataset/notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yooy2hR7BewF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI1kRtc4coU8",
        "colab_type": "text"
      },
      "source": [
        "#Setup data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJRaTjq6Bbc3",
        "colab_type": "text"
      },
      "source": [
        "##Download data first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCQTgOEfBvWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My\\ Drive/PHYS5512/data\n",
        "!mkdir lung_segmentation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA5bv2UAB2eS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd lung_segmentation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgygWIA-B6tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/PHYS5512/kaggle.json /root/.kaggle/\n",
        "!kaggle datasets download -d nikhilpandey360/chest-xray-masks-and-labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c79Ejyvucqr5",
        "colab_type": "text"
      },
      "source": [
        "#Goto the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAYRNeBLctxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/drive/My\\ Drive/PHYS5512/data/lung_segmentation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piHgSS51II7Z",
        "colab_type": "text"
      },
      "source": [
        "#Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "Q-ZV6IcCASVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import os.path as osp\n",
        "from cv2 import imread, createCLAHE \n",
        "import cv2\n",
        "from glob import glob\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH5KYFKpJAQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zipfname = 'chest-xray-masks-and-labels.zip'\n",
        "archive = ZipFile(zipfname)\n",
        "print(len(archive.namelist()))\n",
        "all_files = archive.namelist()\n",
        "all_files[0:10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L6BvTwyGhO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path_prefix = 'Lung Segmentation/CXR_png'\n",
        "mask_path_prefix = 'Lung Segmentation/masks'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2252420ebc0208a088b2efaea43acf460adea99b",
        "id": "ncasKoYAASVR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "They can inspected the concerning dataset seperately [here](http://https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities/home)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "76354e77262b9d98b50eabc96ef25d4885f3ca97",
        "trusted": true,
        "id": "Tk-mdwGQASVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we have 704 masks but 800 images. Hence we are going to\n",
        "# make a 1-1 correspondance from mask to images, not the usual other way.\n",
        "images = [x.split('/')[-1] for x in all_files if x.startswith(image_path_prefix)][1:]\n",
        "masks = [x.split('/')[-1] for x in all_files if x.startswith(mask_path_prefix)][1:]\n",
        "print(images[0:3])\n",
        "print(masks[0:3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LflsgAVLTGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = [fName.split(\".png\")[0] for fName in masks]\n",
        "image_file_name = [fName.split(\"_mask\")[0] for fName in mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCruPOvpNsZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_file_name[0:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD7s_jstNxAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask[0:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e92365a3eb0b6d6e312a21b2134a95a477b8eaba",
        "trusted": true,
        "id": "9kwZfDx5ASVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check = [i for i in mask if \"mask\" in i]\n",
        "print(\"Total mask that has modified name:\",len(check))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGjSVPVtPpe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check[0:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgHrgEFVQOAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_files = set(images) & set(masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAmvBiDsQPPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(testing_files)[0:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "36d6c88771441581093e4c17f82758819c4a795e",
        "id": "I9XezkFqASVW",
        "colab_type": "text"
      },
      "source": [
        "Earlier I was going to train on the Shenzhen dataset while performing prediction on the Montgomery dataset. However, the nature of the data was different in both the set. The images from Shenzhen dataset had **smaller** lung-to-image ratio as compared to the Montgomery dataset.\n",
        "\n",
        "Thus, I am loading the two dataset seperately which I combined once the disparity is understood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c06c55ad639d173daa4bce514a3c1771c3ecb960",
        "trusted": true,
        "id": "S6NflMBRASVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_files = set(images) & set(masks)\n",
        "training_files = check\n",
        "\n",
        "def get_data(X_shape, flag = \"test\"):\n",
        "    im_array = []\n",
        "    mask_array = []\n",
        "    \n",
        "    if flag == \"test\":\n",
        "        for i in tqdm(testing_files):\n",
        "            fi = archive.read(osp.join(image_path_prefix, i))\n",
        "            img = cv2.imdecode(np.frombuffer(fi, np.uint8), 1)\n",
        "            im = cv2.resize(img, (X_shape,X_shape))[:, :, 0]\n",
        "            \n",
        "            fm = archive.read(osp.join(mask_path_prefix, i))\n",
        "            img_fm = cv2.imdecode(np.frombuffer(fm, np.uint8), 1)\n",
        "            mask = cv2.resize(img_fm, (X_shape, X_shape))[:, :, 0]\n",
        "            \n",
        "            im_array.append(im)\n",
        "            mask_array.append(mask)\n",
        "        \n",
        "        return im_array, mask_array\n",
        "    \n",
        "    if flag == \"train\":\n",
        "        for i in tqdm(training_files): \n",
        "            fi = archive.read(osp.join(image_path_prefix, \n",
        "                                       i.split(\"_mask\")[0] + \".png\"))\n",
        "            img = cv2.imdecode(np.frombuffer(fi, np.uint8), 1)\n",
        "            im = cv2.resize(img, (X_shape,X_shape))[:,:,0]\n",
        "            \n",
        "            fm = archive.read(osp.join(mask_path_prefix,i + \".png\"))\n",
        "            img_fm = cv2.imdecode(np.frombuffer(fm, np.uint8), 1)\n",
        "            mask = cv2.resize(img_fm, (X_shape, X_shape))[:,:,0]\n",
        "\n",
        "            im_array.append(im)\n",
        "            mask_array.append(mask)\n",
        "\n",
        "        return im_array, mask_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8adb79d0acf0b5ed3f1b65910d6f8f5e2512773a",
        "trusted": true,
        "id": "ukaE2dxnASVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#perform sanity check\n",
        "\n",
        "def plot_mask(X, y):\n",
        "    sample = []\n",
        "    \n",
        "    for i in range(6):\n",
        "        left = X[i]\n",
        "        right = y[i]\n",
        "        combined = np.hstack((left, right))\n",
        "        sample.append(combined)\n",
        "        \n",
        "    #plt.figure(figsize=(20, 40))\n",
        "    for i in range(0, 6, 2):\n",
        "        ss = sample[i].shape\n",
        "        h, w = ss[0], ss[1]\n",
        "        plt.figure(figsize=(25, 10))\n",
        "        \n",
        "        plt.subplot(3, 2, 1 + i)\n",
        "        plt.imshow(sample[i].reshape([h, w]))\n",
        "        \n",
        "        plt.subplot(3, 2, 2 + i)\n",
        "        plt.imshow(sample[i + 1].reshape([h, w]))\n",
        "        \n",
        "        #plt.subplot(2, 3, 3 + i)\n",
        "        #plt.imshow(sample[i + 2].reshape([h, w]))\n",
        "        \n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b362629edae52f8ca2b558ff621bb50565cbedc4",
        "trusted": true,
        "id": "91RTiJuhASVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load training and testing data\n",
        "dim = 256 * 2\n",
        "X_train,y_train = get_data(dim, flag=\"train\")\n",
        "X_test, y_test = get_data(dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "dbd0220555c692baee8ea509403d64364e2ae439",
        "id": "llqsPIP1ASVb",
        "colab_type": "text"
      },
      "source": [
        "##Perform Sanity Check\n",
        "\n",
        "It is prudent to perform sanity check of the data correspondance. It become a routine check-up after a while but it is very crucial to check if we had made a mistake in loading the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "73be5055a2bf24f67eaf01fe18d0f590ad219553",
        "trusted": true,
        "id": "cofGBSK_ASVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"training set\")\n",
        "plot_mask(X_train, y_train)\n",
        "print(\"testing set\")\n",
        "plot_mask(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a5a309b299cfe2aaa36abd4d175d75f64acba18f",
        "id": "k6AplE6_ASVd",
        "colab_type": "text"
      },
      "source": [
        "Both the sets looks correct. Let's combine them and further use them as a unified dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a65cc256944bf247e150dff8006990d8dafd2185",
        "trusted": true,
        "id": "MKEuYoxcASVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train).reshape(len(X_train),dim,dim,1)\n",
        "y_train = np.array(y_train).reshape(len(y_train),dim,dim,1)\n",
        "X_test = np.array(X_test).reshape(len(X_test),dim,dim,1)\n",
        "y_test = np.array(y_test).reshape(len(y_test),dim,dim,1)\n",
        "assert X_train.shape == y_train.shape\n",
        "assert X_test.shape == y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cJQJUZxaR23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul_hXTgVbYCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('X_train.npy', X_train)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_test.npy', y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfVSF9QpHgZQ",
        "colab_type": "text"
      },
      "source": [
        "#Start from here after pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_im4F9HcGDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.load('X_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE-hzJlNbVKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = np.concatenate((X_train, X_test), axis=0)\n",
        "mask  = np.concatenate((y_train, y_test), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVWx7Tnjdvhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pick_n = 4\n",
        "#ind_check = np.random.choice(len(images), pick_n)\n",
        "ind_check = np.array([622, 170, 611, 309])\n",
        "plt.figure(figsize=(pick_n * 3, pick_n * 6))\n",
        "for i, idx in enumerate(ind_check):\n",
        "  plt.subplot(pick_n, 2, i * 2 + 1)\n",
        "  plt.imshow(images[idx].reshape([512, 512]))\n",
        "  plt.axis('off')\n",
        "  plt.subplot(pick_n, 2, i * 2 + 2)\n",
        "  plt.imshow(mask[idx].reshape([512, 512]))\n",
        "  plt.axis('off')  \n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "04229b3b71c9791087a6d646d49ba213a4211093",
        "id": "cazj03gzASVg",
        "colab_type": "text"
      },
      "source": [
        "#Define  the network and callbacks\n",
        "\n",
        "We are going to use the widely cited [U-Net model](https://arxiv.org/abs/1505.04597) to solve the image segmentation problem. Please read this [excellent overview](https://www.jeremyjordan.me/semantic-segmentation) to understand some basic concepts of semantic image segmentation.\n",
        "\n",
        "First, let us download and visualise the U-net architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aizdaeqEczM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ2MsrmiD7oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='u-net-architecture.png', width=1050)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuhPcclX9qXH",
        "colab_type": "text"
      },
      "source": [
        "##Upsampling via Transpose convolution\n",
        "Before we build the full U-Net model, we need to understand a bit more on how **leanable upsampling** works (i.e. those **green up-conv** 2x2 arrows in the above architecture diagram) in U-net. Transposed Convolution is the most preferred choice to perform up sampling, which basically learns parameters through back propagation to convert a low resolution image to a high resolution image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpx-LII-70es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of using the transpose convolutional layer\n",
        "# adapted from \n",
        "# https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/\n",
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2DTranspose\n",
        "# define input data\n",
        "X = asarray([[1, 2],\n",
        "             [3, 4]])\n",
        "# show input data for context\n",
        "print(X)\n",
        "# reshape input data into one sample a sample with a channel\n",
        "X = X.reshape((1, 2, 2, 1))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2DTranspose(1, (1,1), strides=(2,2), input_shape=(2, 2, 1)))\n",
        "# summarize the model\n",
        "model.summary()\n",
        "# define weights that they do nothing\n",
        "# weights = [asarray([[[[1]]]]), asarray([0])]\n",
        "# store the weights in the model\n",
        "#model.set_weights(weights)\n",
        "# make a prediction with the model\n",
        "yhat = model.predict(X)\n",
        "print(yhat.shape)\n",
        "# reshape output to remove channel to make printing easier\n",
        "yhat = yhat.reshape((4, 4))\n",
        "# summarize output\n",
        "print(yhat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUjNz3OgPwcZ",
        "colab_type": "text"
      },
      "source": [
        "SO why do we really need such \"up-sampling\" at all? The section ***iii) Need for up sampling*** in [this article](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47) provides some intuitive answer:\n",
        "\n",
        "The output of semantic segmentation is not just a class label or some bounding box parameters. In-fact the output is a complete high resolution image in which all the pixels are classified.\n",
        "Thus if we use a regular convolutional network with pooling layers and dense layers, we will lose the “WHERE” information and only retain the “WHAT” information which is not what we want. In case of segmentation we need both “WHAT” as well as “WHERE” information.\n",
        "Hence there is a need to up sample the image, i.e. convert a low resolution image to a high resolution image to recover the “WHERE” information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4Nj02PRVpm9",
        "colab_type": "text"
      },
      "source": [
        "So here is the complete U-Net model. Compared to Keras models developed in prevoius tutorials, this U-Net model has two distinctions:\n",
        "\n",
        "1. it uses the [Keras functional API](https://keras.io/getting-started/functional-api-guide/) to define models\n",
        "2. it defines a new loss function - dice coefficient loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4030463057053ed34371466a0b51584b0310685f",
        "trusted": true,
        "id": "dMZa6PwyASVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import concatenate, Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def unet(input_size=(256, 256, 1)):\n",
        "    inputs = Input(input_size)\n",
        "    \n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[conv10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSJmGepeeTTA",
        "colab_type": "text"
      },
      "source": [
        "Questions:\n",
        "1. Why use Sigmoid as the final activation function?\n",
        "2. What is the rationale behind Dice Coefficient?\n",
        "3. Why do we have to use functional API?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbHIu5ZGPMsa",
        "colab_type": "text"
      },
      "source": [
        "To get a more detailed understanding of U-net, please see the ***Points to note*** section in [this article](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47). Most importantly, the \"skip connection\", which is implemented as keras.concatenate, is important for recovering location information:\n",
        "To get better precise locations, at every step of the decoder we use skip connections by concatenating the output of the transposed convolution layers with the feature maps from the Encoder at the same level:\n",
        "\n",
        "*   u6 = u6' + c4, u6' = upsample(c5)\n",
        "*   u7 = u7' + c3, u7' = upsample(c6)\n",
        "*   u8 = u8' + c2, u8' = upsample(c7)\n",
        "*   u9 = u9' + c1, u9' = upsample(c8)\n",
        "\n",
        "\n",
        "After every concatenation we again apply two consecutive regular convolutions so that the model can learn to assemble a more precise output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hRx6LyndeAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O u-net-upsampling.png  https://www.jeremyjordan.me/content/images/2018/05/Screen-Shot-2018-05-20-at-12.26.53-PM.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7hy8aNldwC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(filename='u-net-upsampling.png', width=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "06d702f1b3957412bb2025c1b4fb3b2a322735d7",
        "id": "Mx8SGeyvASVj",
        "colab_type": "text"
      },
      "source": [
        "## Compile and train the Unet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "37e9815e1fbb5ff29d7ffab156541df200e94e2b",
        "trusted": true,
        "id": "NmXJjjiAASVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = unet(input_size=(512, 512, 1))\n",
        "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss,\n",
        "                  metrics=[dice_coef, 'binary_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ImvlA4linyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_layer_names=False, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHehugHYRz6t",
        "colab_type": "text"
      },
      "source": [
        "The above diagram shows a \"rotated\" U-shape network. Please pay attention to the shape information for each layer (input and output) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9884bf48369bf28f4b0fcb9eb1a1fa4cc4bdd17c",
        "id": "4wkRh1ILASVl",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks, Early Stopping and Reduced LR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6819a68ded3a727ded1b2103b44cd4b8a4988f0f",
        "trusted": true,
        "id": "aNdMB32tASVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "weight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n",
        "\n",
        "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
        "                             save_best_only=True, mode='min', save_weights_only = True)\n",
        "\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
        "                                   patience=3, \n",
        "                                   verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
        "early = EarlyStopping(monitor=\"val_loss\", \n",
        "                      mode=\"min\", \n",
        "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
        "callbacks_list = [checkpoint, early, reduceLROnPlat]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "103a3c9167431a0f4a8279de220fb0f598c11337",
        "id": "mUCZKs7uASVm",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "I intially used a 60-40 train-test spit and got a loss of -0.97. However, the better way to do it is 80-10-10 train-test-validation spit. Below I am roughly doing the later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ddebe9df6f56549a3897fdbfe35a0014eb12040c",
        "scrolled": false,
        "trusted": true,
        "id": "jY_156X5ASVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from keras.optimizers import Adam \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model.compile(optimizer=Adam(lr=2e-4), \n",
        "              loss=[dice_coef_loss], \n",
        "           metrics = [dice_coef, 'binary_accuracy'])\n",
        "\n",
        "train_vol, test_vol, train_seg, test_seg = train_test_split((images - 127.0) / 127.0, \n",
        "                                                            (mask > 127).astype(np.float32), \n",
        "                                                            test_size=0.1, \n",
        "                                                            random_state=2018)\n",
        "\n",
        "train_vol, val_vol, train_seg, val_seg = train_test_split(train_vol, \n",
        "                                                          train_seg, \n",
        "                                                          test_size=0.1, \n",
        "                                                          random_state=2018)\n",
        "\n",
        "loss_history = model.fit(train_vol, train_seg,\n",
        "                         batch_size=16, epochs=5,\n",
        "                         validation_data=(val_vol, val_seg),\n",
        "                         callbacks=callbacks_list)\n",
        "\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "98f61cff65c365a3811d7bc7803a516b98b3d8b9",
        "id": "SOYPHAKoASVo",
        "colab_type": "text"
      },
      "source": [
        "#Plot the metric and evaluate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bb888c80a41662480c712552196e9257bddd3767",
        "trusted": true,
        "id": "OnUT0vByASVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5))\n",
        "ax1.plot(loss_history.history['loss'], '-', label='Loss')\n",
        "ax1.plot(loss_history.history['val_loss'], '-', label='Validation Loss')\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(100 * np.array(loss_history.history['binary_accuracy']), '-', \n",
        "         label = 'Train Binary Accuracy')\n",
        "ax2.plot(100 * np.array(loss_history.history['val_binary_accuracy']), '-',\n",
        "         label = 'Validation Binary Accuracy')\n",
        "ax2.legend()\n",
        "\n",
        "ax3.plot(100 * np.array(loss_history.history['dice_coef']), '-', \n",
        "         label = 'Train Dice Accuracy')\n",
        "ax3.plot(100 * np.array(loss_history.history['val_dice_coef']), '-',\n",
        "         label = 'Validation Dice Accuracy')\n",
        "ax3.legend(loc='best')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCCuXm90olxt",
        "colab_type": "text"
      },
      "source": [
        "**Question** - Why Binary Accuracy is always higher than Dice accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "0b1f54886e584980665a3ee6c64b1d5afbdab681",
        "id": "2bbVZRToASVq",
        "colab_type": "text"
      },
      "source": [
        "#Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "99a79de377e4f0ef780fb99b710081b81fbd31d9",
        "trusted": true,
        "id": "PBrUOZWsASVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_candidates = np.random.randint(1, test_vol.shape[0], 10)\n",
        "preds = model.predict(test_vol)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "for i in range(0,9,3):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    \n",
        "    plt.imshow(np.squeeze(test_vol[pred_candidates[i]]))\n",
        "    plt.xlabel(\"Base Image\")\n",
        "    \n",
        "    \n",
        "    plt.subplot(3, 3, i + 2)\n",
        "    plt.imshow(np.squeeze(test_seg[pred_candidates[i]]))\n",
        "    plt.xlabel(\"Mask\")\n",
        "    \n",
        "    plt.subplot(3, 3, i + 3)\n",
        "    plt.imshow(np.squeeze(preds[pred_candidates[i]]))\n",
        "    plt.xlabel(\"Pridiction\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWlOVnUIor97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}