{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "livereveal": {
      "scroll": "True",
      "theme": "solarized"
    },
    "colab": {
      "name": "Lecture 7 - Autoencoders.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICRAR/PHYS5511/blob/master/2019/week07/Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4qw2epDiXBJ",
        "colab_type": "text"
      },
      "source": [
        "# Original Code\n",
        "\n",
        "https://blog.keras.io/building-autoencoders-in-keras.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL1qhrMIiXBP",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "<div align=\"center\"><img src=\"https://github.com/benjaminirving/mlseminars-autoencoders/blob/master/imgs/d1.png?raw=1\" width=\"80%\"></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ArwvXxKpL4N",
        "colab_type": "text"
      },
      "source": [
        "Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images).\n",
        "\n",
        "\n",
        "We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3wtM09NqgjP",
        "colab_type": "text"
      },
      "source": [
        "# NOTE\n",
        "\n",
        "Switch your runtime to GPU for speed...\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "* Navigate to Editâ†’Notebook Settings\n",
        "* select GPU from the Hardware Accelerator drop-down"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AgUHsXMyvu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIilI-j8iXBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQHnwIAYpTTC",
        "colab_type": "text"
      },
      "source": [
        "We'll start simple, with a single fully-connected neural layer as encoder and as decoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9s2sysniXBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input=input_img, output=decoded)\n",
        "print(\"autoencoder model created\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrXxkuv9peBH",
        "colab_type": "text"
      },
      "source": [
        "Let's also create separate encoder and decoder models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQSmkP7CiXBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this model maps an input to its encoded representation\n",
        "encoder = Model(input=input_img, output=encoded)\n",
        "\n",
        "# create a placeholder for an encoded (32-dimensional) input\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC2fZBxcpxBg",
        "colab_type": "text"
      },
      "source": [
        "Now let's train our autoencoder to reconstruct MNIST digits.\n",
        "\n",
        "First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaw2otT6iXBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rO7_Y6kqBKV",
        "colab_type": "text"
      },
      "source": [
        "Now let's train our autoencoder for 50 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pupi81vEiXBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                nb_epoch=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeicdBXgqroG",
        "colab_type": "text"
      },
      "source": [
        "After 50 epochs, the autoencoder seems to reach a stable train/test loss value of about 0.11. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDbmGMseiXBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(10):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI8YGazAiXBg",
        "colab_type": "text"
      },
      "source": [
        "# Deep autoencoder\n",
        "\n",
        "We do not have to limit ourselves to a single layer as encoder or decoder, we could instead use a stack of layers, such as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz67couoiXBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, \n",
        "                x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMA-nK48rbXQ",
        "colab_type": "text"
      },
      "source": [
        "After 100 epochs, it reaches a train and test loss of ~0.1, a bit worse than our previous models. Our reconstructed digits look a bit better too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3p_lIT9riko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(10):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "84Z5rV6PiXBj",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBMAsQdhiXBk",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/benjaminirving/mlseminars-autoencoders/blob/master/imgs/d5.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpfQqgcXiXBl",
        "colab_type": "text"
      },
      "source": [
        "Since our inputs are images, it makes sense to use convolutional neural networks (convnets) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better.\n",
        "\n",
        "Let's implement one. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY7ln5nPiXBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOYeWsXVuK2Z",
        "colab_type": "text"
      },
      "source": [
        "To train it, we will use the original MNIST digits with shape (samples, 3, 28, 28), and we will just normalize pixel values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrT6hFf1iXBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  \n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBQbzAW5uYx1",
        "colab_type": "text"
      },
      "source": [
        "Let's train this model for 50 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLIeL3JyiXBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKCDd_H3iXBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(10):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}